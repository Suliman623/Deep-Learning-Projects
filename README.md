# Deep Learning Course Projects

A comprehensive collection of 16 deep learning mini-projects covering fundamental to advanced concepts in neural networks, computer vision, NLP, and generative models.

## üìã Projects Overview

| # | Project | Key Topics | Results |
|---|---------|------------|---------|
| 1 | Backpropagation & MNIST | Neural Networks, Backpropagation | 98.03% Validation Accuracy |
| 2 | Adaptive Optimizers | SGD, RMSProp, Adam, Adagrad | 92.35% Accuracy (RMSProp) |
| 3 | Convolutional Networks | CNN, BatchNorm, Dropout | 85.20% Test Accuracy |
| 4 | CNN Image Recognition | CNN Architecture, Regularization | >80% All Milestones |
| 5 | Encoder-Decoder NMT | Seq2Seq, Attention, Beam Search | 21.45 BLEU Score |
| 6 | Transfer Learning | Fine-tuning, ResNet, Data Augmentation | 99.95% Accuracy |
| 7 | RNN Name Generation | Character-level RNN, Language Modeling | Successful Name Generation |
| 8 | CNN Interpretability | Feature Visualization, ResNet50 | Layer-wise Activation Analysis |
| 9 | Large-scale Text Analysis | Neural Networks, Regression | 0.09116 MSE |
| 10 | Parameter Efficient FT | LoRA, Prompt Tuning, PEFT | 1.1% Parameters Trained |
| 11 | Prompt Engineering | CoT, Base Models, Few-shot Learning | 63.64% Accuracy |
| 12 | PyTorch Basics | PyTorch, MNIST Classification | 95.7% Test Accuracy |
| 13 | Question Search Engine | BERT, Transformers, Similarity | 92.60% Accuracy |
| 14 | Transformers | GPT-2, Self-attention, NLP Tasks | Custom Implementation |
| 15 | Variational Autoencoder | VAE, Generative Models, CelebA | Successful Face Generation |
| 16 | Word Embeddings | BoW, TF-IDF, GloVe, Classification | 85.6% Accuracy |

## üõ†Ô∏è Technologies Used

- **Frameworks**: PyTorch, TensorFlow, Hugging Face, PEFT
- **Architectures**: CNN, RNN, LSTM, GRU, Transformer, VAE
- **Techniques**: Transfer Learning, Attention, Fine-tuning, Regularization
- **Tools**: GPU Acceleration, Data Augmentation, Model Interpretability

## üöÄ Getting Started

Each project contains its own implementation, dataset details, and training procedures. Navigate to individual project folders for specific instructions.

## üìä Key Achievements

- **Computer Vision**: Achieved >98% on MNIST, >85% on custom datasets
- **NLP**: Implemented full NMT pipeline with 21.45 BLEU score
- **Efficiency**: PEFT methods with only 1.1% parameter updates
- **Generative Models**: Successful VAE implementation for face generation

## üìù Course Insights

This collection demonstrates progressive learning from basic neural networks to advanced topics like transformers, generative models, and parameter-efficient fine-tuning, showcasing both theoretical understanding and practical implementation skills.

---

